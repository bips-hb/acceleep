% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils-modelling.R
\name{cuda_close_device}
\alias{cuda_close_device}
\title{Release GPU memory manually}
\usage{
cuda_close_device(device = 0)
}
\arguments{
\item{device}{\verb{[0]}: The numeric ID of the GPU device to close. To close
multiple devices, use \code{device = c(0, 1)}.}
}
\value{
Nothing
}
\description{
This is a wrapper for a python call via \code{\link[reticulate:py_run]{reticulate::py_run_string()}}
that calls the \code{numba} python module to close one or more CUDA devices.
This ensures that GPU memory is freed up after / before modelling.
}
\details{
The \code{numba} module has to be available but is not automatically
installed by e.g. \code{\link[keras:install_keras]{keras::install_keras()}}. You can manually install it
via \code{reticulate::conda_install("acceleep", "numba")} in a \code{conda} env
named \code{"acceleep"}.
}
\note{
See \url{https://github.com/rstudio/keras/issues/739}
}
\examples{
\dontrun{
# Some model fitting here
# ...
# Before new models are fit, free up memory just in case:
cuda_close_device(0)

# New model fitting here
}
}
